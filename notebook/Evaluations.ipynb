{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a93f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e742c429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b060ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bad0143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"For customer-facing applications, which company's models dominate the top rankings?\",\n",
    "    \"What percentage of respondents are using RAG in some form?\",\n",
    "    \"How often are most respondents updating their models?\",\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\",\n",
    "    \"70% of respondents are using RAG in some form.\",\n",
    "    \"More than 50% update their models at least monthly, with 17% doing so weekly.\",\n",
    "]\n",
    "\n",
    "# Dataset\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "csv_path = \"C:\\\\utube project\\\\llmops-by-sunny-saviya\\\\LLMOps_series\\\\data\\\\ai_report_qa_pairs.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5256fb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['2d094ee7-fe5d-49bc-87df-fda85c30d229',\n",
       "  '3b17d1f5-d8e8-41c9-8541-4a5127f4be7f',\n",
       "  '9f373186-c710-4d02-925c-017086cf3e6b'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"LLMopsdatset\"\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Input and expected output pairs for AgenticAIReport\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e2cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\utube project\\\\llmops-by-sunny-saviya\\\\LLMOps_series\")\n",
    "\n",
    "from pathlib import Path\n",
    "from multi_doc_chat.src.document_ingestion.data_ingestion import ChatIngestor\n",
    "from multi_doc_chat.src.document_chat.retrieval import ConversationalRAG\n",
    "import os\n",
    "\n",
    "# Simple file adapter for local file paths\n",
    "class LocalFileAdapter:\n",
    "    \"\"\"Adapter for local file paths to work with ChatIngestor.\"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = Path(file_path)\n",
    "        self.name = self.path.name\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "\n",
    "\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = \"C:\\\\utube project\\\\llmops-by-sunny-saviya\\\\LLMOps_series\\\\data\\\\AI_and_ML_Agentic_AI_Notes.txt\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the AI Engineering Report using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the AI Engineering Report text file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        \n",
    "        # Create file adapter\n",
    "        file_adapter = LocalFileAdapter(data_path)\n",
    "        \n",
    "        # Build index using ChatIngestor\n",
    "        ingestor = ChatIngestor(\n",
    "            temp_base=\"data\",\n",
    "            faiss_base=\"faiss_index\",\n",
    "            use_session_dirs=True\n",
    "        )\n",
    "        \n",
    "        # Build retriever\n",
    "        ingestor.built_retriver(\n",
    "            uploaded_files=[file_adapter],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get session ID and index path\n",
    "        session_id = ingestor.session_id\n",
    "        index_path = f\"faiss_index/{session_id}\"\n",
    "        \n",
    "        # Create RAG instance and load retriever\n",
    "        rag = ConversationalRAG(session_id=session_id)\n",
    "        rag.load_retriever_from_faiss(\n",
    "            index_path=index_path,\n",
    "            k=k,\n",
    "            index_name=os.getenv(\"FAISS_INDEX_NAME\", \"index\")\n",
    "        )\n",
    "        \n",
    "        # Get answer\n",
    "        answer = rag.invoke(question, chat_history=[])\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-google-genai\n",
    "# !pip install langchain-groq\n",
    "# !pip install structlog\n",
    "# !pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3adda1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2026-01-01T13:42:58.615758Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:58.616753Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:58.616753Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:42:58.617752Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:42:58.619796Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191258_a0773a4e\", \"temp_dir\": \"data\\\\session_20260101_191258_a0773a4e\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191258_a0773a4e\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:42:58.621794Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191258_a0773a4e\\\\48a3196a.txt\", \"timestamp\": \"2026-01-01T13:42:58.623796Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:42:58.624847Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:42:58.625968Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:42:58.629232Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191258_a0773a4e\", \"timestamp\": \"2026-01-01T13:42:59.477252Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:42:59.479342Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.481350Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.483814Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.484921Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:42:59.484921Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:42:59.491974Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:42:59.494188Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191258_a0773a4e\", \"timestamp\": \"2026-01-01T13:42:59.543971Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191258_a0773a4e\", \"timestamp\": \"2026-01-01T13:42:59.545158Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.546031Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.546031Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:42:59.546031Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:42:59.546031Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:42:59.550928Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:42:59.550928Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191258_a0773a4e\", \"timestamp\": \"2026-01-01T13:42:59.588404Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191258_a0773a4e\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191258_a0773a4e\", \"timestamp\": \"2026-01-01T13:42:59.588404Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191258_a0773a4e\", \"user_input\": \"For customer-facing applications, which company's models dominate the top rankings?\", \"answer_preview\": \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\", \"timestamp\": \"2026-01-01T13:43:01.764913Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: For customer-facing applications, which company's models dominate the top rankings?\n",
      "\n",
      "Answer: OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a sample question\n",
    "test_input = {\"question\": \"For customer-facing applications, which company's models dominate the top rankings?\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac863b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "# faiss-cpu is already installed via requirements.txt\n",
    "# faiss-gpu is not available for Windows via pip\n",
    "# !pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9aaa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bbe392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0da6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith[vcr] in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (3.11.5)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (2.12.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (2.32.5)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (0.12.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from langsmith[vcr]) (0.25.0)\n",
      "Collecting vcrpy>=7.0.0 (from langsmith[vcr])\n",
      "  Downloading vcrpy-8.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: anyio in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith[vcr]) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith[vcr]) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith[vcr]) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith[vcr]) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith[vcr]) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith[vcr]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith[vcr]) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith[vcr]) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith[vcr]) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith[vcr]) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith[vcr]) (2.6.2)\n",
      "Requirement already satisfied: PyYAML in c:\\utube project\\llmops-by-sunny-saviya\\.venv\\lib\\site-packages (from vcrpy>=7.0.0->langsmith[vcr]) (6.0.3)\n",
      "Collecting wrapt (from vcrpy>=7.0.0->langsmith[vcr])\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading vcrpy-8.1.0-py3-none-any.whl (42 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-win_amd64.whl (60 kB)\n",
      "Installing collected packages: wrapt, vcrpy\n",
      "\n",
      "   ---------------------------------------- 2/2 [vcrpy]\n",
      "\n",
      "Successfully installed vcrpy-8.1.0 wrapt-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install langsmith\n",
    "# !pip install langchain\n",
    "# !pip install \"langsmith[vcr]\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f78c372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.answer_ai_report_question(inputs: dict, data_path: str = 'C:\\\\utube project\\\\llmops-by-sunny-saviya\\\\LLMOps_series\\\\data\\\\AI_and_ML_Agentic_AI_Notes.txt', chunk_size: int = 1000, chunk_overlap: int = 200, k: int = 5) -> dict>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ai_report_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8bb0dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2026-01-01T13:43:13.787161Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:13.788157Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:13.789156Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:13.790153Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:13.792153Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191313_c187c31a\", \"temp_dir\": \"data\\\\session_20260101_191313_c187c31a\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191313_c187c31a\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:13.793634Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191313_c187c31a\\\\9998f80f.txt\", \"timestamp\": \"2026-01-01T13:43:13.795780Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:13.796777Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:13.799778Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:13.799778Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191313_c187c31a\", \"timestamp\": \"2026-01-01T13:43:14.530181Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:14.531187Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.532685Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.532685Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.533694Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:14.533694Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:14.537098Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:14.537098Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191313_c187c31a\", \"timestamp\": \"2026-01-01T13:43:14.580331Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191313_c187c31a\", \"timestamp\": \"2026-01-01T13:43:14.580331Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.582431Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.583821Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:14.583821Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:14.584971Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:14.589014Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:14.590017Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191313_c187c31a\", \"timestamp\": \"2026-01-01T13:43:14.627373Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191313_c187c31a\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191313_c187c31a\", \"timestamp\": \"2026-01-01T13:43:14.628711Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191313_c187c31a\", \"user_input\": \"For customer-facing applications, which company's models dominate the top rankings?\", \"answer_preview\": \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\", \"timestamp\": \"2026-01-01T13:43:16.180655Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.183560Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.184595Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.184595Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:16.185967Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:16.189374Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191316_eb0b65cf\", \"temp_dir\": \"data\\\\session_20260101_191316_eb0b65cf\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191316_eb0b65cf\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:16.190446Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191316_eb0b65cf\\\\91b0d212.txt\", \"timestamp\": \"2026-01-01T13:43:16.192876Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:16.193875Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:16.195704Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:16.197573Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: For customer-facing applications, which company's models dominate the top rankings?\n",
      "A1: OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191316_eb0b65cf\", \"timestamp\": \"2026-01-01T13:43:16.731219Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:16.732633Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.732633Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.732633Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.732633Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:16.735677Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:16.737319Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:16.737319Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191316_eb0b65cf\", \"timestamp\": \"2026-01-01T13:43:16.774162Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191316_eb0b65cf\", \"timestamp\": \"2026-01-01T13:43:16.774162Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.779079Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.780077Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:16.780077Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:16.781078Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:16.783075Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:16.783075Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191316_eb0b65cf\", \"timestamp\": \"2026-01-01T13:43:16.822348Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191316_eb0b65cf\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191316_eb0b65cf\", \"timestamp\": \"2026-01-01T13:43:16.823349Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191316_eb0b65cf\", \"user_input\": \"What percentage of respondents are using RAG in some form?\", \"answer_preview\": \"70% of respondents are using RAG in some form.\", \"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:18.289684Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191318_9ab27df2\", \"temp_dir\": \"data\\\\session_20260101_191318_9ab27df2\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191318_9ab27df2\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:18.306032Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191318_9ab27df2\\\\58c4c9fd.txt\", \"timestamp\": \"2026-01-01T13:43:18.306032Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:18.306032Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:18.306032Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:18.310413Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: What percentage of respondents are using RAG in some form?\n",
      "A2: 70% of respondents are using RAG in some form.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191318_9ab27df2\", \"timestamp\": \"2026-01-01T13:43:18.837775Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:18.837775Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.840703Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.841718Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.841718Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:18.842928Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:18.844926Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:18.844926Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191318_9ab27df2\", \"timestamp\": \"2026-01-01T13:43:18.882298Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191318_9ab27df2\", \"timestamp\": \"2026-01-01T13:43:18.882298Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.884299Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.885295Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:18.886297Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:18.886297Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:18.888296Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:18.888296Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191318_9ab27df2\", \"timestamp\": \"2026-01-01T13:43:18.936974Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191318_9ab27df2\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191318_9ab27df2\", \"timestamp\": \"2026-01-01T13:43:18.939207Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191318_9ab27df2\", \"user_input\": \"How often are most respondents updating their models?\", \"answer_preview\": \"More than 50% update their models at least monthly, with 17% doing so weekly.\", \"timestamp\": \"2026-01-01T13:43:20.078734Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: How often are most respondents updating their models?\n",
      "A3: More than 50% update their models at least monthly, with 17% doing so weekly.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Test with all golden questions\n",
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(inputs, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda3141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "519dab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-agenticAIReport-qa-rag-bd173ea7' at:\n",
      "https://smith.langchain.com/o/30627a25-f995-4e3b-8724-5e02aab0f561/datasets/28607798-db0a-4bcd-acf3-dafb101d7667/compare?selectedSessions=c6e7fc18-15c1-4c7c-90d4-d1b144c9a883\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2026-01-01T13:43:30.095708Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.096709Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.097709Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:30.097709Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:30.100773Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191330_aa470523\", \"temp_dir\": \"data\\\\session_20260101_191330_aa470523\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191330_aa470523\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:30.101773Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191330_aa470523\\\\3db755ca.txt\", \"timestamp\": \"2026-01-01T13:43:30.102770Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:30.103941Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:30.105293Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:30.106449Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191330_aa470523\", \"timestamp\": \"2026-01-01T13:43:30.819564Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:30.821029Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.822039Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.822039Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.822039Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:30.822039Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:30.822039Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:30.826507Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191330_aa470523\", \"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191330_aa470523\", \"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:30.863612Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:30.868089Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:30.869518Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191330_aa470523\", \"timestamp\": \"2026-01-01T13:43:30.905055Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191330_aa470523\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191330_aa470523\", \"timestamp\": \"2026-01-01T13:43:30.905055Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191330_aa470523\", \"user_input\": \"For customer-facing applications, which company's models dominate the top rankings?\", \"answer_preview\": \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\", \"timestamp\": \"2026-01-01T13:43:32.505037Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "1it [00:02,  2.41s/it]{\"timestamp\": \"2026-01-01T13:43:32.510337Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:32.510337Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:32.511415Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:32.511415Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:32.515698Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191332_b5071fa1\", \"temp_dir\": \"data\\\\session_20260101_191332_b5071fa1\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191332_b5071fa1\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:32.517918Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191332_b5071fa1\\\\2e90f3ab.txt\", \"timestamp\": \"2026-01-01T13:43:32.519450Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:32.520738Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:32.522131Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:32.522131Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191332_b5071fa1\", \"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:33.058650Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:33.069654Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:33.072799Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191332_b5071fa1\", \"timestamp\": \"2026-01-01T13:43:33.115723Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191332_b5071fa1\", \"timestamp\": \"2026-01-01T13:43:33.117133Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.119518Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.120516Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:33.120516Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:33.121519Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:33.124938Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:33.125457Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191332_b5071fa1\", \"timestamp\": \"2026-01-01T13:43:33.161277Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191332_b5071fa1\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191332_b5071fa1\", \"timestamp\": \"2026-01-01T13:43:33.161277Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191332_b5071fa1\", \"user_input\": \"What percentage of respondents are using RAG in some form?\", \"answer_preview\": \"70% of respondents are using RAG in some form.\", \"timestamp\": \"2026-01-01T13:43:34.706863Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "2it [00:04,  2.29s/it]{\"timestamp\": \"2026-01-01T13:43:34.710999Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:34.710999Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:34.712010Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:34.712010Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:34.715484Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191334_8761a9b0\", \"temp_dir\": \"data\\\\session_20260101_191334_8761a9b0\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191334_8761a9b0\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:43:34.717466Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191334_8761a9b0\\\\d7268af9.txt\", \"timestamp\": \"2026-01-01T13:43:34.719508Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:43:34.720507Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:43:34.721506Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:34.722981Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191334_8761a9b0\", \"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:35.355633Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:35.363601Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:43:35.363601Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191334_8761a9b0\", \"timestamp\": \"2026-01-01T13:43:35.398434Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191334_8761a9b0\", \"timestamp\": \"2026-01-01T13:43:35.399432Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.401435Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.401435Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:43:35.403436Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:43:35.404429Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:43:35.406431Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:43:35.406431Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191334_8761a9b0\", \"timestamp\": \"2026-01-01T13:43:35.445861Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191334_8761a9b0\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191334_8761a9b0\", \"timestamp\": \"2026-01-01T13:43:35.446869Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191334_8761a9b0\", \"user_input\": \"How often are most respondents updating their models?\", \"answer_preview\": \"More than 50% update their models at least monthly, with 17% doing so weekly.\", \"timestamp\": \"2026-01-01T13:43:36.529293Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "3it [00:06,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Use evaluator string directly instead of LangChainStringEvaluator\n",
    "dataset_name = \"LLMopsdatset\"\n",
    "\n",
    "# Run evaluation using our RAG function\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    # evaluators=[\"cot_qa\"],  # Pass evaluator string directly\n",
    "    experiment_prefix=\"test-agenticAIReport-qa-rag\",\n",
    "    # Experiment metadata\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43bbd94",
   "metadata": {},
   "source": [
    "## Custom Correctness Evaluator\n",
    "\n",
    "Creating an LLM-as-a-Judge evaluator to assess semantic and factual alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2032e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def correctness_evaluator(run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Custom LLM-as-a-Judge evaluator for correctness.\n",
    "    \n",
    "    Correctness means how well the actual model output matches the reference output \n",
    "    in terms of factual accuracy, coverage, and meaning.\n",
    "    \n",
    "    Args:\n",
    "        run: The Run object containing the actual outputs\n",
    "        example: The Example object containing the expected outputs\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'score' (1 for correct, 0 for incorrect) and 'reasoning'\n",
    "    \"\"\"\n",
    "    # Extract actual and expected outputs\n",
    "    actual_output = run.outputs.get(\"answer\", \"\")\n",
    "    expected_output = example.outputs.get(\"answer\", \"\")\n",
    "    input_question = example.inputs.get(\"question\", \"\")\n",
    "    \n",
    "    # Define the evaluation prompt\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an evaluator whose job is to judge correctness.\n",
    "\n",
    "Correctness means how well the actual model output matches the reference output in terms of factual accuracy, coverage, and meaning.\n",
    "\n",
    "- If the actual output matches the reference output semantically (even if wording differs), it should be marked correct.\n",
    "- If the output misses key facts, introduces contradictions, or is factually incorrect, it should be marked incorrect.\n",
    "\n",
    "Do not penalize for stylistic or formatting differences unless they change meaning.\"\"\"),\n",
    "        (\"human\", \"\"\"<example>\n",
    "<input>\n",
    "{input}\n",
    "</input>\n",
    "\n",
    "<output>\n",
    "Expected Output: {expected_output}\n",
    "\n",
    "Actual Output: {actual_output}\n",
    "</output>\n",
    "</example>\n",
    "\n",
    "Please grade the following agent run given the input, expected output, and actual output.\n",
    "Focus only on correctness (semantic and factual alignment).\n",
    "\n",
    "Respond with:\n",
    "1. A brief reasoning (1-2 sentences)\n",
    "2. A final verdict: either \"CORRECT\" or \"INCORRECT\"\n",
    "\n",
    "Format your response as:\n",
    "Reasoning: [your reasoning]\n",
    "Verdict: [CORRECT or INCORRECT]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Initialize LLM (using Gemini as shown in your config)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Create chain and invoke\n",
    "    chain = eval_prompt | llm\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\n",
    "            \"input\": input_question,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"actual_output\": actual_output\n",
    "        })\n",
    "        \n",
    "        response_text = response.content\n",
    "        \n",
    "        # Parse the response\n",
    "        reasoning = \"\"\n",
    "        verdict = \"\"\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"Reasoning:\"):\n",
    "                reasoning = line.replace(\"Reasoning:\", \"\").strip()\n",
    "            elif line.startswith(\"Verdict:\"):\n",
    "                verdict = line.replace(\"Verdict:\", \"\").strip()\n",
    "        \n",
    "        # Convert verdict to score (1 for correct, 0 for incorrect)\n",
    "        score = 1 if \"CORRECT\" in verdict.upper() else 0\n",
    "        \n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": score,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"comment\": f\"Verdict: {verdict}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": 0,\n",
    "            \"reasoning\": f\"Error during evaluation: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9ebaf",
   "metadata": {},
   "source": [
    "### Run Evaluation with Custom Correctness Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb02b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'agenticAIReport-correctness-eval-9e71e17d' at:\n",
      "https://smith.langchain.com/o/30627a25-f995-4e3b-8724-5e02aab0f561/datasets/28607798-db0a-4bcd-acf3-dafb101d7667/compare?selectedSessions=f12b561c-8839-4ca3-947b-7056b393efb8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]{\"timestamp\": \"2026-01-01T13:46:03.897233Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:03.899240Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:03.900529Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:03.900529Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:03.903907Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191603_721554c1\", \"temp_dir\": \"data\\\\session_20260101_191603_721554c1\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191603_721554c1\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:46:03.905973Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191603_721554c1\\\\78717969.txt\", \"timestamp\": \"2026-01-01T13:46:03.907490Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:46:03.908490Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:46:03.909874Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:03.911685Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191603_721554c1\", \"timestamp\": \"2026-01-01T13:46:04.592438Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:46:04.594732Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.596738Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.597738Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.597738Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:04.598854Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:04.603408Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:46:04.603408Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191603_721554c1\", \"timestamp\": \"2026-01-01T13:46:04.639707Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191603_721554c1\", \"timestamp\": \"2026-01-01T13:46:04.641090Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.642451Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.643458Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:04.643458Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:04.644660Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:04.646668Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:04.647670Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191603_721554c1\", \"timestamp\": \"2026-01-01T13:46:04.687105Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191603_721554c1\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191603_721554c1\", \"timestamp\": \"2026-01-01T13:46:04.688108Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191603_721554c1\", \"user_input\": \"For customer-facing applications, which company's models dominate the top rankings?\", \"answer_preview\": \"OpenAI models dominate, with 3 of the top 5 and half of the top 10 most popular models for customer-facing apps.\", \"timestamp\": \"2026-01-01T13:46:06.215726Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent \"HTTP/1.1 200 OK\"\n",
      "1it [00:06,  6.49s/it]{\"timestamp\": \"2026-01-01T13:46:10.384073Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:10.385083Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:10.385083Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:10.387244Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:10.389585Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191610_4aecbb0c\", \"temp_dir\": \"data\\\\session_20260101_191610_4aecbb0c\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191610_4aecbb0c\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:46:10.392845Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191610_4aecbb0c\\\\df72b2b3.txt\", \"timestamp\": \"2026-01-01T13:46:10.394980Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:46:10.395980Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:46:10.398982Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:10.400489Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191610_4aecbb0c\", \"timestamp\": \"2026-01-01T13:46:11.068439Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:46:11.069438Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.072631Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.073618Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.073618Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:11.074720Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:11.077152Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:46:11.078176Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191610_4aecbb0c\", \"timestamp\": \"2026-01-01T13:46:11.128198Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191610_4aecbb0c\", \"timestamp\": \"2026-01-01T13:46:11.129209Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.131410Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.132415Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:11.132415Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:11.133692Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:11.137085Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:11.137085Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191610_4aecbb0c\", \"timestamp\": \"2026-01-01T13:46:11.183032Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191610_4aecbb0c\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191610_4aecbb0c\", \"timestamp\": \"2026-01-01T13:46:11.184004Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191610_4aecbb0c\", \"user_input\": \"What percentage of respondents are using RAG in some form?\", \"answer_preview\": \"70% of respondents are using RAG in some form.\", \"timestamp\": \"2026-01-01T13:46:12.944151Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent \"HTTP/1.1 200 OK\"\n",
      "2it [00:13,  6.94s/it]{\"timestamp\": \"2026-01-01T13:46:17.645640Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:17.647136Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:17.647136Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:17.648774Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:17.651289Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"session_id\": \"session_20260101_191617_878d7693\", \"temp_dir\": \"data\\\\session_20260101_191617_878d7693\", \"faiss_dir\": \"faiss_index\\\\session_20260101_191617_878d7693\", \"sessionized\": true, \"timestamp\": \"2026-01-01T13:46:17.654296Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"AI_and_ML_Agentic_AI_Notes.txt\", \"saved_as\": \"data\\\\session_20260101_191617_878d7693\\\\a9bcdc3a.txt\", \"timestamp\": \"2026-01-01T13:46:17.656294Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2026-01-01T13:46:17.658291Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 1, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2026-01-01T13:46:17.658291Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:17.659351Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20260101_191617_878d7693\", \"timestamp\": \"2026-01-01T13:46:18.338239Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2026-01-01T13:46:18.339238Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.340244Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.341338Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.342592Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:18.342592Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:18.345602Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.0-flash\", \"timestamp\": \"2026-01-01T13:46:18.346615Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191617_878d7693\", \"timestamp\": \"2026-01-01T13:46:18.393937Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20260101_191617_878d7693\", \"timestamp\": \"2026-01-01T13:46:18.394939Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.397472Z\", \"level\": \"info\", \"event\": \"Running in LOCAL mode: .env loaded\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.398632Z\", \"level\": \"info\", \"event\": \"Loaded GROQ_API_KEY from individual env var\"}\n",
      "{\"timestamp\": \"2026-01-01T13:46:18.400141Z\", \"level\": \"info\", \"event\": \"Loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GROQ_API_KEY\": \"gsk_jV...\", \"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2026-01-01T13:46:18.400141Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"config_keys\": [\"embedding_model\", \"retriever\", \"llm\"], \"timestamp\": \"2026-01-01T13:46:18.402496Z\", \"level\": \"info\", \"event\": \"YAML config loaded\"}\n",
      "{\"model\": \"models/text-embedding-004\", \"timestamp\": \"2026-01-01T13:46:18.403505Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "{\"session_id\": \"session_20260101_191617_878d7693\", \"timestamp\": \"2026-01-01T13:46:18.444494Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20260101_191617_878d7693\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20260101_191617_878d7693\", \"timestamp\": \"2026-01-01T13:46:18.444494Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents \"HTTP/1.1 200 OK\"\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "{\"session_id\": \"session_20260101_191617_878d7693\", \"user_input\": \"How often are most respondents updating their models?\", \"answer_preview\": \"More than 50% update their models at least monthly, with 17% doing so weekly.\", \"timestamp\": \"2026-01-01T13:46:19.669174Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n",
      "AFC is enabled with max remote calls: 10.\n",
      "HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent \"HTTP/1.1 200 OK\"\n",
      "3it [00:24,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed! Check the LangSmith UI for detailed results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation with the custom correctness evaluator\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Define evaluators - using custom correctness evaluator\n",
    "evaluators = [correctness_evaluator]\n",
    "\n",
    "dataset_name = \"LLMopsdatset\"\n",
    "\n",
    "# Run evaluation\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=evaluators,\n",
    "    experiment_prefix=\"agenticAIReport-correctness-eval\",\n",
    "    description=\"Evaluating RAG system with custom correctness evaluator (LLM-as-a-Judge)\",\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"evaluator\": \"custom_correctness_llm_judge\",\n",
    "        \"model\": \"gemini-2.5-pro\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation completed! Check the LangSmith UI for detailed results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788216b0",
   "metadata": {},
   "source": [
    "### Optional: Combine Multiple Evaluators\n",
    "\n",
    "You can use multiple evaluators together to get different perspectives on your RAG system's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "256a9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Combine custom correctness evaluator with langsmith built-in evaluators\n",
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Combine custom and built-in evaluators\n",
    "# Pass evaluator strings directly instead of using LangChainStringEvaluator\n",
    "combined_evaluators = [\n",
    "    correctness_evaluator,  # Custom LLM-as-a-Judge\n",
    "    \"cot_qa\",  # Chain-of-thought QA evaluator (as string)\n",
    "]\n",
    "\n",
    "# Run evaluation with multiple evaluators\n",
    "# Uncomment to run:\n",
    "# experiment_results_combined = evaluate(\n",
    "#     answer_ai_report_question,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=combined_evaluators,\n",
    "#     experiment_prefix=\"agenticAIReport-multi-eval\",\n",
    "#     description=\"Evaluating RAG system with multiple evaluators\",\n",
    "#     metadata={\n",
    "#         \"variant\": \"RAG with FAISS\",\n",
    "#         \"evaluators\": \"correctness + cot_qa\",\n",
    "#         \"chunk_size\": 1000,\n",
    "#         \"chunk_overlap\": 200,\n",
    "#         \"k\": 5,\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f3e7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b7c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
